{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thunguyen177/lda_pca/blob/master/LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "BRil9JdCgNjG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let $A$ be the matrix that contains the eigenvectors of $W^{-1}B$ in the descending order of the corresponding eigenvalues. Let\n",
        "\n",
        "$Y=XA$ \n",
        "\n",
        "then the $(i,j)$-position of $Y$ is equal to $X_{i.}A_{j.}$, which is the $j^{th}$ discriminant for observation $X_{i.}$\n",
        "\n",
        "$Y=\\begin{pmatrix}Y_1\\\\Y_2\\\\\\vdots\\\\Y_s\\end{pmatrix}$ has  mean $\\mu_{iY}$ under population $\\pi_k$\n",
        "\n",
        "We allocate observation $x$ to $\\pi_k$ if \n",
        "\n",
        "$(y-\\mu_{kY})'(y-\\mu_{kY})\\le (y-\\mu_{iY})'(y-\\mu_{iY}) \\forall i\\neq k$"
      ]
    },
    {
      "metadata": {
        "id": "Jwe7q_XgkAou",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def find_mean_vectors(X, y):\n",
        "    labels = np.unique(y)\n",
        "    num_classes = labels.shape[0]\n",
        "    mean_vectors = []\n",
        "    for l in labels:\n",
        "        mean_vectors.append(np.mean(X[y==l], axis=0))\n",
        "    return mean_vectors\n",
        "\n",
        "def within(X, y):\n",
        "    labels = np.unique(y)\n",
        "    num_classes = labels.shape[0]\n",
        "    num_features = X.shape[1]\n",
        "    mean_vectors = find_mean_vectors(X, y)\n",
        "    W = np.zeros((num_features, num_features))\n",
        "    for label, mv in zip(labels, mean_vectors):\n",
        "        class_sc_mat = np.zeros((num_features, num_features))                 \n",
        "        for row in X[y == label]:\n",
        "            row, mv = row.reshape(num_features, 1), mv.reshape(num_features, 1)\n",
        "            class_sc_mat += (row-mv).dot((row-mv).T)\n",
        "        W += class_sc_mat                           \n",
        "    return W\n",
        "\n",
        "def between(X, y):\n",
        "    overall_mean = np.mean(X, axis=0)\n",
        "    num_features = X.shape[1]\n",
        "    mean_vectors = find_mean_vectors(X, y)    \n",
        "    B = np.zeros((num_features, num_features))\n",
        "    for i, mean_vec in enumerate(mean_vectors):  \n",
        "        n = X[y==i+1,:].shape[0]\n",
        "        mean_vec = mean_vec.reshape(num_features, 1)\n",
        "        overall_mean = overall_mean.reshape(num_features, 1)\n",
        "        B += n * (mean_vec - overall_mean).dot((mean_vec - overall_mean).T)\n",
        "    return B\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IAfLZ9dmx9T-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(X,y,Xtest,ytest):\n",
        "    W, B = within(X, y), between(X, y)\n",
        "    eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(W).dot(B))\n",
        "    ids = np.argsort(eig_vals)[::-1]\n",
        "    A = eig_vecs[ids,] \n",
        "    r = (eig_vals != 0).sum()\n",
        "    labels = np.unique(y)\n",
        "    mean_vectors = find_mean_vectors(X, y)\n",
        "    g =labels.size\n",
        "    A = eig_vecs[ids[range(r)]]  \n",
        "    predicted_labels = []\n",
        "    for idx in range(Xtest.shape[0]):\n",
        "      x = Xtest[idx,:]\n",
        "      p = []\n",
        "      s = []\n",
        "      for i in range(g):\n",
        "        pr = []\n",
        "        for j in range(r):\n",
        "          pr = np.append([pr],[(A[j].dot(x-mean_vectors[i]))**2])\n",
        "        s = np.append([s],[pr.sum()])\n",
        "      predicted_labels = np.append([predicted_labels],[labels[np.argmin(s)]])  \n",
        "    num_correct = (predicted_labels == ytest).sum()\n",
        "    correct_rate = num_correct/float(ytest.size)\n",
        "    \n",
        "    return predicted_labels, correct_rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Xg0ZJnCpV1x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "52d859e5-bd1c-4eac-ea3e-e1ce04a7e003"
      },
      "cell_type": "code",
      "source": [
        "mean1 = [0, 0]\n",
        "mean2 = [3,4]\n",
        "mean3 = [5,5]\n",
        "cov = [[1, 0], [0, 2]]  # diagonal covariance\n",
        "def generate_data(n):\n",
        "  x1 = np.random.multivariate_normal(mean1, cov, n)\n",
        "  x2 = np.random.multivariate_normal(mean2, cov, n)\n",
        "  x3 = np.random.multivariate_normal(mean3, cov, n)\n",
        "  X = np.concatenate((x1, x2,x3), axis=0)\n",
        "  y = np.concatenate([np.repeat(1,n),np.repeat(2,n),np.repeat(3,n)])\n",
        "  return X,y\n",
        "\n",
        "X,y = generate_data(30)\n",
        "Xtest,ytest = generate_data(20)\n",
        "\n",
        "predicted_labels, correct_rate = predict(X,y,Xtest,ytest)\n",
        "predicted_labels"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1.,\n",
              "       1., 2., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 2., 2., 2.,\n",
              "       3., 2., 1., 3., 2., 2., 3., 3., 2., 3., 3., 2., 3., 3., 2., 3., 3.,\n",
              "       3., 3., 3., 3., 3., 3., 3., 2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "metadata": {
        "id": "LWJw7qFD_QG4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "851f9901-3d6f-4f2e-8d00-414a15cff673"
      },
      "cell_type": "code",
      "source": [
        "correct_rate"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8333333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QUVR2yZhjHxh"
      },
      "cell_type": "markdown",
      "source": [
        "# Fisher discriminant analysis:\n",
        "\\begin{align*}\n",
        "B &= \\sum_{i=1}^gn_i(\\bar{x}_i-\\bar{x})(\\bar{x}_i-\\bar{x})'\\\\\n",
        "W &=  \\sum_{i=1}^g(n_i-1)S_i\n",
        "\\end{align*}\n",
        "\n",
        "Let $\\hat{\\lambda}_1,...,\\hat{\\lambda}_s$ be the increasing nonzero eigenvalues of $W^{-1}B$ and $\\hat{a}_1,...,\\hat{a}_s$ be their eigenvectors, respectively.\n",
        "\n",
        "Let $r$ be the number of nonzero eigenvalues of $W^{-1}B$ .\n",
        "Then, $x\\rightarrow \\pi_k$ if $s_k=\\sum_{j=1}^r[a'_j(x-\\bar{x}_k)]^2\\le (s_i=)\\sum_{j=1}^r[a'_j(x-\\bar{x}_i)]^2\\forall i\\neq k$ \n"
      ]
    }
  ]
}